{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae909e6c",
   "metadata": {},
   "source": [
    "# Actividad 1: Métricas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc4e8d",
   "metadata": {},
   "source": [
    "Vamos a comenzar cargando el .csv proporcionado como material de la práctica y definiendo una serie de funciones que nos permitirán calcular todas las métricas de regresión estudiadas en sesiones de teoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51316cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y objetivo</th>\n",
       "      <th>Predicciones M1</th>\n",
       "      <th>Predicciones M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.00</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y objetivo  Predicciones M1  Predicciones M2\n",
       "0        2.50              3.0              2.0\n",
       "1        3.00              2.9              2.0\n",
       "2        1.60              2.0              2.0\n",
       "3        8.00              8.1              7.0\n",
       "4        4.56              4.0              5.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_1 = pd.read_csv('l2p1.csv')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15271bb",
   "metadata": {},
   "source": [
    "Vemos que el fichero está compuesto por tres columnas:\n",
    "\n",
    "- ``Y objetivo``: Valores reales de la variable contínua a predecir.\n",
    "- ``Predicciones M1``: Valores predichos por el modelo M1.\n",
    "- ``Predicciones M2``: Valores predichos por el modelo M2.\n",
    "\n",
    "Calcularemos las métricas de regresión sobre los valores de las predicciones. Pasamos a definir las funciones de cálculo de dichas magnitudes. Por cuestiones de eficiencia, utilizaremos arrays ``numpy`` y sus funciones predefinidas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d65865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(x_real, x_pred):\n",
    "    return (1 / len(x_real)) * np.sum(np.abs(x_real - x_pred))\n",
    "\n",
    "def mean_squared_error(x_real, x_pred):\n",
    "    return (1 / len(x_real)) * np.sum(np.square(x_real - x_pred))\n",
    "\n",
    "def root_mean_squared_error(x_real, x_pred):\n",
    "    return np.sqrt((1 / len(x_real)) * np.sum(np.square(x_real - x_pred)))\n",
    "\n",
    "def mean(x):\n",
    "    return np.sum(x) / len(x)\n",
    "\n",
    "def variance(x):\n",
    "    return np.sqrt(np.sum(np.square(x - mean(x))))    \n",
    "\n",
    "def covariance(x1, x2):\n",
    "    return np.sum((x1 - mean(x1)) * (x2 - mean(x2)))\n",
    "\n",
    "def coef_det(x_real, x_pred):\n",
    "    return covariance(x_real, x_pred) / (variance(x_real) * variance(x_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0b853",
   "metadata": {},
   "source": [
    "Pasamos a continuación a obtener las métricas para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5864b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_objetivo = np.array(df_1['Y objetivo'].values)\n",
    "pred_m1 = np.array(df_1['Predicciones M1'].values)\n",
    "pred_m2 = np.array(df_1['Predicciones M2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961b58a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio absoluto de M1 1.0396666666666667\n",
      "Error cuadrático medio de M1 7.983049999999999\n",
      "Raíz del error cuadrático medio de M1 2.8254291709402306\n",
      "Coeficiente de determinación de M1 0.7925094612153079\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las métricas para M1\n",
    "print(f'Error medio absoluto de M1 {mean_absolute_error(y_objetivo, pred_m1)}')\n",
    "print(f'Error cuadrático medio de M1 {mean_squared_error(y_objetivo, pred_m1)}')\n",
    "print(f'Raíz del error cuadrático medio de M1 {root_mean_squared_error(y_objetivo, pred_m1)}')\n",
    "print(f'Coeficiente de determinación de M1 {coef_det(y_objetivo, pred_m1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9480c653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio absoluto de M2 0.6113333333333333\n",
      "Error cuadrático medio de M2 0.5219533333333333\n",
      "Raíz del error cuadrático medio de M2 0.7224633785413163\n",
      "Coeficiente de determinación de M2 0.9892110230257817\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las métricas para M2\n",
    "print(f'Error medio absoluto de M2 {mean_absolute_error(y_objetivo, pred_m2)}')\n",
    "print(f'Error cuadrático medio de M2 {mean_squared_error(y_objetivo, pred_m2)}')\n",
    "print(f'Raíz del error cuadrático medio de M2 {root_mean_squared_error(y_objetivo, pred_m2)}')\n",
    "print(f'Coeficiente de determinación de M2 {coef_det(y_objetivo, pred_m2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f6e32",
   "metadata": {},
   "source": [
    "Viendo los resultados obtenidos parece una mejor elección elegir el modelo M2 en lugar del M1. Esto es así porque, por una parte, los errores medios tienen un valor más bajo con M2 mientras que el coeficiente de correlación presenta un valor más cercano a 1 con las predicciones de M2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a05687",
   "metadata": {},
   "source": [
    "# Actividad 2: Métricas de clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7385cd",
   "metadata": {},
   "source": [
    "De nuevo, comenzamos cargando el .csv proporcionado como material de la práctica y definiendo las funciones necesarias para calcular la matriz de confusión, así como todas las métricas de clasificación solicitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8148317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clase Objetivo</th>\n",
       "      <th>Predicciones M1</th>\n",
       "      <th>Predicciones M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clase Objetivo  Predicciones M1  Predicciones M2\n",
       "0               0                1                0\n",
       "1               0                0                0\n",
       "2               0                0                0\n",
       "3               1                1                1\n",
       "4               1                1                1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv('l2p2.csv')\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a624d",
   "metadata": {},
   "source": [
    "La composición de este fichero es similar a la estudiada en el ejercicio anterior. La única diferencia reside en el hecho de que, al estar estudiando una clasificación binaria, las clases se denotan como 0 ó 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba1baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(x_real, x_pred):\n",
    "    # Vamos a hacer una definición general de esta función, es decir, \n",
    "    # se podrá utilizar en problemas de clasificación en dos o más clases.\n",
    "    # Obtenemos las diferentes clases del problema\n",
    "    classes = np.unique(x_real)\n",
    "    n = len(classes)\n",
    "    # Definimos la matriz inicialmente toda a 0s\n",
    "    matrix = np.zeros(shape = (n, n))\n",
    "    # Comenzamos a rellenar la matriz\n",
    "    for i in range(n):\n",
    "        # Obtenemos la clase actual\n",
    "        current_class = classes[i]\n",
    "        # Posiciones donde el valor real vale current_class\n",
    "        pos1 = np.where(x_real == current_class)\n",
    "        for j in range(n):\n",
    "            # Obtenemos las posiciones de la classes[j]\n",
    "            pos2 = np.where(x_pred == classes[j])\n",
    "            # Contamos los aciertos/fallos viendo en cuantas posiciones\n",
    "            # coinciden pos1 y pos2.\n",
    "            # Si classes[j] == current_class las posiciones donde coinciden\n",
    "            # pos1 y pos2 son los aciertos\n",
    "            # Si classes[j] != currenc_class las posiciones donde coinciden\n",
    "            # pos1 y pos2 son los fallos del modelo\n",
    "            matrix[i, j] = len(np.intersect1d(pos1, pos2))\n",
    "    return matrix\n",
    "            \n",
    "def true_values(matrix):\n",
    "    # Los valores correctamente clasificados se encuentran en la diagonal\n",
    "    # de la matriz de confusión\n",
    "    return np.diagonal(matrix)    \n",
    "    \n",
    "def accuracy(matrix):\n",
    "    return np.sum(true_values(matrix)) / np.sum(matrix)\n",
    "\n",
    "def recall(matrix):\n",
    "    sum_rows = np.sum(matrix, axis = 1)\n",
    "    return true_values(matrix) / sum_rows\n",
    "\n",
    "def fp_rate(matrix):\n",
    "    sum_columns = np.sum(matrix, axis = 0)\n",
    "    fp = sum_columns - true_values(matrix)\n",
    "    tn = np.zeros((1, len(matrix))).flatten()\n",
    "    for i in range(len(matrix)):\n",
    "        tn[i] = np.sum(np.delete(np.delete(matrix, i, axis = 0), i, axis = 1))\n",
    "    return fp / (tn + fp)\n",
    "    \n",
    "    #sum_columns = np.sum(matrix, axis = 0)\n",
    "    #sum_rows = np.zeros((1, len(matrix)))\n",
    "    #for i in range(len(sum_rows)):\n",
    "    #    sum_rows[i] = np.sum(np.delete(matrix, i, axis = 0))\n",
    "    #return (sum_columns - true_values(matrix)) / sum_rows.flatten()\n",
    "\n",
    "def specificity(matrix):\n",
    "    sum_columns = np.sum(matrix, axis = 0)\n",
    "    fp = sum_columns - true_values(matrix)\n",
    "    tn = np.zeros((1, len(matrix))).flatten()\n",
    "    for i in range(len(matrix)):\n",
    "        tn[i] = np.sum(np.delete(np.delete(matrix, i, axis = 0), i, axis = 1))\n",
    "    return tn / (tn + fp)\n",
    "    \n",
    "    \n",
    "    #true_val = true_values(matrix)\n",
    "    #aux_true = np.zeros((1, len(true_val)))\n",
    "    #sum_rows = np.zeros((1, len(matrix)))\n",
    "    #for i in range(len(aux_true)):\n",
    "    #    aux_true[i] = np.sum(np.delete(true_val, i))\n",
    "    #    sum_rows[i] = np.sum(np.delete(matrix, i, axis = 0))\n",
    "    #return aux_true.flatten() / sum_rows.flatten()\n",
    "\n",
    "def precission(matrix):\n",
    "    sum_columns = np.sum(matrix, axis = 0)\n",
    "    return true_values(matrix) / sum_columns\n",
    "\n",
    "def f1_score(matrix):\n",
    "    prec = precission(matrix)\n",
    "    rec = recall(matrix)\n",
    "    return (2 * prec * rec) / (prec + rec)\n",
    "\n",
    "def kappa(matrix):\n",
    "    p0 = accuracy(matrix)\n",
    "    sum_rows = np.sum(matrix, axis = 1)\n",
    "    sum_columns = np.sum(matrix, axis = 0)\n",
    "    pe = (1 / (np.sum(matrix) ** 2)) * np.sum(sum_rows * sum_columns)\n",
    "    return (p0 - pe) / (1 - pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebfdeca",
   "metadata": {},
   "source": [
    "Obtenemos la matriz de confusión de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800c324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_objetivo = np.array(df_2['Clase Objetivo'].values)\n",
    "pred_m1 = np.array(df_2['Predicciones M1'].values)\n",
    "pred_m2 = np.array(df_2['Predicciones M2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa50d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.,  1.],\n",
       "       [ 4.,  6.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_m1 = confusion_matrix(y_objetivo, pred_m1)\n",
    "conf_m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18c962",
   "metadata": {},
   "source": [
    "Para las predicciones de M1 vemos la siguiente distribución de aciertos/fallos:\n",
    "\n",
    "- Verdaderos positivos: 19 elementos clasificados correctamente como 0.\n",
    "- Verdaderos negativos: 6 elementos clasificados correctamente como 1.\n",
    "- Falsos positivos: 1 elemento clasificado incorrectamente como 0.\n",
    "- Falsos negativos: 4 elementos clasificados incorrectamente como 1.\n",
    "\n",
    "Sumando la diagonal podemos observar como se obtienten 25 clasificaciones correctas de 30 patrones a clasificar. Vamos a obtener las métricas de esta clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd672e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCR M1 -> 0.8333333333333334\n",
      "Recall M1 -> 0.95\n",
      "FP Rate M1 -> 0.4\n",
      "Especifidad M1 -> 0.6\n",
      "Precisión M1 -> 0.8260869565217391\n",
      "F1-Score M1 -> 0.8837209302325583\n",
      "Kappa M1 -> 0.5945945945945946\n"
     ]
    }
   ],
   "source": [
    "print(f'CCR M1 -> {accuracy(conf_m1)}')\n",
    "print(f'Recall M1 -> {recall(conf_m1)[0]}')\n",
    "print(f'FP Rate M1 -> {fp_rate(conf_m1)[0]}')\n",
    "print(f'Especifidad M1 -> {specificity(conf_m1)[0]}')\n",
    "print(f'Precisión M1 -> {precission(conf_m1)[0]}')\n",
    "print(f'F1-Score M1 -> {f1_score(conf_m1)[0]}')\n",
    "print(f'Kappa M1 -> {kappa(conf_m1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d3c6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.,  8.],\n",
       "       [ 1.,  9.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_m2 = confusion_matrix(y_objetivo, pred_m2)\n",
    "conf_m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb490c7",
   "metadata": {},
   "source": [
    "Para las predicciones de M2 vemos la siguiente distribución de aciertos/fallos:\n",
    "\n",
    "- Verdaderos positivos: 12 elementos clasificados correctamente como 0.\n",
    "- Verdaderos negativos: 9 elementos clasificados correctamente como 1.\n",
    "- Falsos positivos: 8 elemento clasificado incorrectamente como 0.\n",
    "- Falsos negativos: 1 elementos clasificados incorrectamente como 1.\n",
    "\n",
    "Sumando la diagonal podemos observar como se obtienten 21 clasificaciones correctas de 30 patrones a clasificar. Vamos a obtener las métricas de esta clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f07a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCR M2 -> 0.7\n",
      "Recall M2 -> 0.6\n",
      "FP Rate M2 -> 0.1\n",
      "Especifidad M2 -> 0.9\n",
      "Precisión M2 -> 0.9230769230769231\n",
      "F1-Score M2 -> 0.7272727272727274\n",
      "Kappa M2 -> 0.42553191489361697\n"
     ]
    }
   ],
   "source": [
    "print(f'CCR M2 -> {accuracy(conf_m2)}')\n",
    "print(f'Recall M2 -> {recall(conf_m2)[0]}')\n",
    "print(f'FP Rate M2 -> {fp_rate(conf_m2)[0]}')\n",
    "print(f'Especifidad M2 -> {specificity(conf_m2)[0]}')\n",
    "print(f'Precisión M2 -> {precission(conf_m2)[0]}')\n",
    "print(f'F1-Score M2 -> {f1_score(conf_m2)[0]}')\n",
    "print(f'Kappa M2 -> {kappa(conf_m2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc7f47",
   "metadata": {},
   "source": [
    "Viendo los resultados obtenidos, el modelo M1 parece obtener valores más favorables en todas las métricas de clasificación. Obtiene una precisión más alta, un recall más alto y por tanto, un valor F1 más alto, lo que comparativamente hace que el modelo M1 sea más favorable en este caso particular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e1ff0",
   "metadata": {},
   "source": [
    "# Cuestión 3: Clasificación y métricas en tres clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe09b3",
   "metadata": {},
   "source": [
    "Vamos a construir los resultados propuestos en el manual de la actividad como un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782a68eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gato</th>\n",
       "      <th>Perro</th>\n",
       "      <th>Loro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gato</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perro</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loro</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gato  Perro  Loro\n",
       "Gato     20     10     5\n",
       "Perro     5     30     0\n",
       "Loro      5      5    25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = pd.DataFrame({\"Gato\": [20, 5, 5], \"Perro\": [10, 30, 5], \"Loro\": [5, 0, 25]}, \n",
    "                   index = [\"Gato\", \"Perro\", \"Loro\"])\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7436f7f",
   "metadata": {},
   "source": [
    "Construimos otro DataFrame donde mostramos las métricas de regresión para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c52f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FP Rate</th>\n",
       "      <th>Especifidad</th>\n",
       "      <th>Precisión</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gato</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perro</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loro</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CCR    Recall   FP Rate  Especifidad  Precisión  F1-Score  \\\n",
       "Gato   0.714286  0.571429  0.142857     0.857143   0.666667  0.615385   \n",
       "Perro  0.714286  0.857143  0.214286     0.785714   0.666667  0.750000   \n",
       "Loro   0.714286  0.714286  0.071429     0.928571   0.833333  0.769231   \n",
       "\n",
       "          Kappa  \n",
       "Gato   0.571429  \n",
       "Perro  0.571429  \n",
       "Loro   0.571429  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"CCR\", \"Recall\", \"FP Rate\", \"Especifidad\", \"Precisión\", \"F1-Score\", \"Kappa\"]\n",
    "rows = [\"Gato\", \"Perro\", \"Loro\"]\n",
    "matrix_df = np.array(df_3.values)\n",
    "ccr = accuracy(matrix_df)\n",
    "rec = recall(matrix_df)\n",
    "fp_r = fp_rate(matrix_df)\n",
    "esp = specificity(matrix_df)\n",
    "prec = precission(matrix_df)\n",
    "f1_s = f1_score(matrix_df)\n",
    "kappas = kappa(matrix_df)\n",
    "aux = [ccr, rec, fp_r, esp, prec, f1_s, kappas]\n",
    "df_res = pd.DataFrame({x:y for (x, y) in zip(columns, aux)}, index = rows)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094745f",
   "metadata": {},
   "source": [
    "El valor CCR es igual en todas las filas pues es un valor de precisión global que, en este caso, alcanza el 71.4285% de valores predichos correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ae858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
