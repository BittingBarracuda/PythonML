{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación de una red neuronal convolucional con el *Rock, Paper & Scissors Data Set*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos realizando la carga del *Rock, Paper & Scissors Data Set* mediante la librería ``tensorflow_datasets``. Indicaremos mediante sus parámetros que queremos un split entrenamiento/test y que lo utilizaremos para un algoritmo de Deep Learning Supervisado.\n",
    "\n",
    "Se puede observar como disponemos de imágenes de 300x300 píxeles con tres niveles de colog (RGB), de ahí que los datos estén dispuestos en \"matrices\" 300x300x3. Contamos con 2520 instancias de entrenamiento y 372 de testing.\n",
    "\n",
    "Se puede plantear la problemática de si estos datos son suficientes para realizar un entrenamiento efectivo de nuestro algoritmo de Deep Learning. Si bien no mostramos todo el proceso en este cuaderno, se realizó un entrenamiento con los datos proporcionados y se produjeron dos casuísticas.\n",
    "\n",
    "1.- Para redes convolucionales sencillas (dos capas convolucionales y pocos nodos por capa) se producía un claro *underfitting* pues no se superaba una *accuracy* del 40% en ninguno de los conjuntos.\n",
    "\n",
    "2.- Para redes convolucionales más complejas, se producía un rápido *overfitting* dónde se alcanzaba una *accuracy* próxima al 100% en el conjunto de entrenamiento, y un rendimiento muy pobre en el conjunto de test.\n",
    "\n",
    "Para solucionarlo, proponemos un procedimiento de aumentado artificial de la información que explicamos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520, 300, 300, 3)\n",
      "(2520,)\n",
      "(372, 300, 300, 3)\n",
      "(372,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#BATCH_SIZE = 32\n",
    "(X_train, y_train), (X_test, y_test) = tfds.as_numpy(tfds.load('rock_paper_scissors', \n",
    "                                                    split = ['train', 'test'],\n",
    "                                                    batch_size = -1,\n",
    "                                                    as_supervised = True))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.97647059, 0.97647059, 0.97647059]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98823529, 0.98823529, 0.98823529]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.96862745, 0.96862745, 0.96862745],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97254902, 0.97254902, 0.97254902]],\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97254902, 0.97254902, 0.97254902]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.96862745, 0.96862745, 0.96862745],\n",
       "         [0.98039216, 0.98039216, 0.98039216]]],\n",
       "\n",
       "\n",
       "       [[[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98431373, 0.98431373, 0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97647059, 0.97647059, 0.97647059]],\n",
       "\n",
       "        [[0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216]]],\n",
       "\n",
       "\n",
       "       [[[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.94509804, 0.94509804, 0.94509804],\n",
       "         [0.94509804, 0.94509804, 0.94509804],\n",
       "         [0.94117647, 0.94117647, 0.94117647]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.93333333, 0.93333333, 0.93333333],\n",
       "         [0.93333333, 0.93333333, 0.93333333],\n",
       "         [0.94901961, 0.94901961, 0.94901961]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.94117647, 0.94117647, 0.94117647],\n",
       "         [0.9372549 , 0.9372549 , 0.9372549 ],\n",
       "         [0.93333333, 0.93333333, 0.93333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.94117647, 0.94117647, 0.94117647],\n",
       "         [0.94509804, 0.94509804, 0.94509804],\n",
       "         [0.94117647, 0.94117647, 0.94117647]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.93333333, 0.93333333, 0.93333333],\n",
       "         [0.93333333, 0.93333333, 0.93333333],\n",
       "         [0.94117647, 0.94117647, 0.94117647]],\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9372549 , 0.9372549 ],\n",
       "         [0.9372549 , 0.9372549 , 0.9372549 ],\n",
       "         [0.93333333, 0.93333333, 0.93333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.97647059, 0.97647059, 0.97647059]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         ...,\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         ...,\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216]]],\n",
       "\n",
       "\n",
       "       [[[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.93333333, 0.93333333, 0.93333333]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.95686275, 0.95686275, 0.95686275],\n",
       "         [0.94117647, 0.94117647, 0.94117647]],\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9372549 , 0.9372549 ],\n",
       "         [0.95294118, 0.95294118, 0.95294118],\n",
       "         [0.94509804, 0.94509804, 0.94509804]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         ...,\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.98039216, 0.98039216, 0.98039216]]],\n",
       "\n",
       "\n",
       "       [[[0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.94509804, 0.94509804, 0.94509804],\n",
       "         [0.95686275, 0.95686275, 0.95686275]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.95294118, 0.95294118, 0.95294118]],\n",
       "\n",
       "        [[0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.95294118, 0.95294118, 0.95294118],\n",
       "         [0.94901961, 0.94901961, 0.94901961],\n",
       "         [0.94509804, 0.94509804, 0.94509804]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         ...,\n",
       "         [0.98039216, 0.98039216, 0.98039216],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.98039216, 0.98039216, 0.98039216]],\n",
       "\n",
       "        [[0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059]],\n",
       "\n",
       "        [[0.98431373, 0.98431373, 0.98431373],\n",
       "         [0.98823529, 0.98823529, 0.98823529],\n",
       "         [0.98431373, 0.98431373, 0.98431373],\n",
       "         ...,\n",
       "         [0.97254902, 0.97254902, 0.97254902],\n",
       "         [0.97647059, 0.97647059, 0.97647059],\n",
       "         [0.97647059, 0.97647059, 0.97647059]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos con el aumentado de datas mediante la clase ``ImageDataGenerator``, esta clase permite tomar imágenes y realizar transformaciones en base a los parámetros que fijemos. En este caso, la clase realizará aleatoriamente las siguientes transformaciones sobre las imágenes del conjunto de datos:\n",
    "\n",
    "1.- Desplazado horiziontal y vertical indicado en porcentaje de la imágen a desplazar (en nuestro caso 20% como máximo).\n",
    "\n",
    "2.- Volteado horizontal de la imágen.\n",
    "\n",
    "3.- Rotado de la imágen desde 0 a 360º. \n",
    "\n",
    "4.- Zoom sobre la imágen. En este caso, un 30% de zoom \"hacia fuera\" (zoom in) o \"hacia dentro\" (zoom out) sobre la imágen.\n",
    "\n",
    "Mediante esta clase podremos generar un iterador sobre nuestro conjunto de datos que aplicará de forma aleatoria estas transformaciones. De esta forma, logramos un aumentado del número de instancias sobre las que realizar nuestro entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "                            width_shift_range = 0.2,\n",
    "                            height_shift_range = 0.2,\n",
    "                            horizontal_flip = True,\n",
    "                            rotation_range = 360,\n",
    "                            zoom_range = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente obtenemos el número de clases y el número de instancias por clase. Podemos observar como el dataset tiene 3 clases (piedra, papel o tijera representadas como 0, 1 o 2) y 840 instancias por clase (por lo que es un conjunto de datos equilibrado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[840 840 840]\n"
     ]
    }
   ],
   "source": [
    "classes, n_instances = np.unique(y_train, return_counts = True)\n",
    "print(classes)\n",
    "print(n_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que nuestra red tendrá una capa de salida con activación ``softmax`` debemos codificar nuestra variable objetivo como *one-hot* utilizando la función ``to_categorical`` de ``Keras``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = classes.size\n",
    "\n",
    "y_train_oh = to_categorical(y_train, n_classes)\n",
    "y_test_oh = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez visto esto, procedemos a realizar el entrenamiento de nuestra red neuronal convolucional. Nuestra red tendrá la siguiente topología.\n",
    "\n",
    "- Una capa convolucional ``Conv2D`` con 32 filtros, ventana de kernel 3x3 y activación ReLu.\n",
    "- Seguida de una capa ``MaxPooling2D`` 2x2 que produce un *downsampling* de la salida generada por las capas convolucionales.\n",
    "- Una capa ``Dropout`` con una tasa de puesta a 0 del 10% para evitar el *overfitting*.\n",
    "- Esta estructura se repite 3 veces y finalmente conecta con una capa ``Flatten`` que funciona como capa de entrada de la red neuronal de salida. Esta capa tiene tantos nodos como características tienen nuestras instancias.\n",
    "- Capa oculta ``Dense`` con 128 nodos y función de activación ReLu.\n",
    "- Capa ``Dropout`` para paliar el *overfitting*.\n",
    "- Capa de salida con función de activación ``softmax`` para obtener la probabilidad de pertenencia a cada clase.\n",
    "\n",
    "De nuevo, utilizaremos la ``categorical_crossentropy`` como función de pérdida y el algoritmo de Adam como algoritmo de optimización de los pesos y parámetros de nuestra red. Como hemos explicado anteriormente, generaremos un iterador sobre el ``ImageDataGenerator`` para aplicar transformaciones al conjunto de entrada. Estas transformaciones se utilizarán durante el entrenamiento del modelo descrito. \n",
    "\n",
    "Debido a que este cuaderno se ejecutó en un sistema sin GPU compatible con ``TensorFlow``, únicamente computaremos 25 iteraciones del algoritmo, pues la demora es muy significativa. Puede observarse sin embargo en las gráficas de más abajo, que los resultados podrían mejorar si se hubiesen computado más iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmart\\AppData\\Local\\Temp\\ipykernel_3036\\3986678955.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(iterator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "79/79 [==============================] - 139s 2s/step - loss: 1.4963 - accuracy: 0.3512 - val_loss: 1.0985 - val_accuracy: 0.3387\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 128s 2s/step - loss: 1.0833 - accuracy: 0.3857 - val_loss: 1.0382 - val_accuracy: 0.5403\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 130s 2s/step - loss: 1.0349 - accuracy: 0.4433 - val_loss: 0.9387 - val_accuracy: 0.6156\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.9590 - accuracy: 0.5044 - val_loss: 0.8234 - val_accuracy: 0.6290\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.8515 - accuracy: 0.5889 - val_loss: 0.6948 - val_accuracy: 0.6694\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.7925 - accuracy: 0.6028 - val_loss: 0.7522 - val_accuracy: 0.6478\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.7236 - accuracy: 0.6643 - val_loss: 0.5853 - val_accuracy: 0.7742\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.6477 - accuracy: 0.7036 - val_loss: 0.5623 - val_accuracy: 0.7124\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.5722 - accuracy: 0.7556 - val_loss: 0.3769 - val_accuracy: 0.8522\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.5355 - accuracy: 0.7627 - val_loss: 0.5578 - val_accuracy: 0.7204\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.5034 - accuracy: 0.7976 - val_loss: 0.3741 - val_accuracy: 0.8710\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.4555 - accuracy: 0.8159 - val_loss: 0.3354 - val_accuracy: 0.9059\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.4158 - accuracy: 0.8333 - val_loss: 0.3201 - val_accuracy: 0.9113\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.4269 - accuracy: 0.8242 - val_loss: 0.3592 - val_accuracy: 0.8790\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.3803 - accuracy: 0.8591 - val_loss: 0.5332 - val_accuracy: 0.7688\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 126s 2s/step - loss: 0.3802 - accuracy: 0.8504 - val_loss: 0.8099 - val_accuracy: 0.6962\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 125s 2s/step - loss: 0.4813 - accuracy: 0.8052 - val_loss: 0.6167 - val_accuracy: 0.7151\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 129s 2s/step - loss: 0.4170 - accuracy: 0.8353 - val_loss: 0.3462 - val_accuracy: 0.8790\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.3462 - accuracy: 0.8615 - val_loss: 0.3364 - val_accuracy: 0.9140\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 125s 2s/step - loss: 0.3458 - accuracy: 0.8698 - val_loss: 0.2506 - val_accuracy: 0.9435\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.3022 - accuracy: 0.8857 - val_loss: 0.2401 - val_accuracy: 0.9247\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 124s 2s/step - loss: 0.2809 - accuracy: 0.8964 - val_loss: 0.3655 - val_accuracy: 0.8575\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.2736 - accuracy: 0.8984 - val_loss: 0.3285 - val_accuracy: 0.8844\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.3077 - accuracy: 0.8925 - val_loss: 0.3032 - val_accuracy: 0.8952\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.2641 - accuracy: 0.9063 - val_loss: 0.2915 - val_accuracy: 0.9140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.496301</td>\n",
       "      <td>0.351190</td>\n",
       "      <td>1.098493</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.083251</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>1.038177</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.034949</td>\n",
       "      <td>0.443254</td>\n",
       "      <td>0.938724</td>\n",
       "      <td>0.615591</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.958997</td>\n",
       "      <td>0.504365</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.851455</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.694788</td>\n",
       "      <td>0.669355</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.792544</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>0.647849</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.723571</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.585326</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.647659</td>\n",
       "      <td>0.703571</td>\n",
       "      <td>0.562306</td>\n",
       "      <td>0.712366</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.572234</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.376929</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.535541</td>\n",
       "      <td>0.762698</td>\n",
       "      <td>0.557764</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.503372</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.374069</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.455453</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.335420</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.415752</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.320082</td>\n",
       "      <td>0.911290</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.426892</td>\n",
       "      <td>0.824206</td>\n",
       "      <td>0.359165</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.859127</td>\n",
       "      <td>0.533202</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.380163</td>\n",
       "      <td>0.850397</td>\n",
       "      <td>0.809893</td>\n",
       "      <td>0.696237</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.481278</td>\n",
       "      <td>0.805159</td>\n",
       "      <td>0.616748</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.417032</td>\n",
       "      <td>0.835317</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.346205</td>\n",
       "      <td>0.861508</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>0.913979</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.250637</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.302231</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.240096</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.280910</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.365514</td>\n",
       "      <td>0.857527</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.273637</td>\n",
       "      <td>0.898413</td>\n",
       "      <td>0.328511</td>\n",
       "      <td>0.884409</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.307746</td>\n",
       "      <td>0.892460</td>\n",
       "      <td>0.303158</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.264121</td>\n",
       "      <td>0.906349</td>\n",
       "      <td>0.291456</td>\n",
       "      <td>0.913979</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   1.496301  0.351190  1.098493      0.338710      0\n",
       "1   1.083251  0.385714  1.038177      0.540323      1\n",
       "2   1.034949  0.443254  0.938724      0.615591      2\n",
       "3   0.958997  0.504365  0.823419      0.629032      3\n",
       "4   0.851455  0.588889  0.694788      0.669355      4\n",
       "5   0.792544  0.602778  0.752246      0.647849      5\n",
       "6   0.723571  0.664286  0.585326      0.774194      6\n",
       "7   0.647659  0.703571  0.562306      0.712366      7\n",
       "8   0.572234  0.755556  0.376929      0.852151      8\n",
       "9   0.535541  0.762698  0.557764      0.720430      9\n",
       "10  0.503372  0.797619  0.374069      0.870968     10\n",
       "11  0.455453  0.815873  0.335420      0.905914     11\n",
       "12  0.415752  0.833333  0.320082      0.911290     12\n",
       "13  0.426892  0.824206  0.359165      0.879032     13\n",
       "14  0.380318  0.859127  0.533202      0.768817     14\n",
       "15  0.380163  0.850397  0.809893      0.696237     15\n",
       "16  0.481278  0.805159  0.616748      0.715054     16\n",
       "17  0.417032  0.835317  0.346154      0.879032     17\n",
       "18  0.346205  0.861508  0.336365      0.913979     18\n",
       "19  0.345800  0.869841  0.250637      0.943548     19\n",
       "20  0.302231  0.885714  0.240096      0.924731     20\n",
       "21  0.280910  0.896429  0.365514      0.857527     21\n",
       "22  0.273637  0.898413  0.328511      0.884409     22\n",
       "23  0.307746  0.892460  0.303158      0.895161     23\n",
       "24  0.264121  0.906349  0.291456      0.913979     24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = random.seed(time.time())\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Generamos la siguiente estructura de capas:\n",
    "# 1.- Capa convolucional con 32 neuronas, tamaño de kernel 3x3, activación ReLU y regularizador L2 para evitar overfitting.\n",
    "# 2.- Capa MaxPooling con tamaño 2x2 para realizar downsampling.\n",
    "# 3.- Capa dropout con tasa del 0.3 para, de nuevo, tratar de evitar overfitting.\n",
    "# Esta estructura se repite 3 veces de forma secuencial\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), input_shape = (300, 300, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.1, seed = seed))\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.1, seed = seed))\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.1, seed = seed))\n",
    "# Red neuronal de salida, su capa de entrada tendrá tantos nodos como características\n",
    "# tenga cada instancia del problema. Para ello usamos Flatten(). \n",
    "model.add(Flatten())\n",
    "# Capa oculta (densa) de la red neuronal de salida con 128 neuronas y activacion ReLu\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.2, seed = seed))\n",
    "# Capa de salida con activación softmax y tantos nodos como clases tenga el problema\n",
    "# Esta capa nos devolverá la probabilidad de pertenencia a cada clase.\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "# Compilamos el modelo utilizando categorical_crossentropy como función de pérdida, optimización con algoritmo de Adam\n",
    "# y accuracy como métrica del rendimiento.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# Creamos el iterador de data_gen\n",
    "iterator = data_gen.flow(X_train, y_train_oh)\n",
    "history = model.fit_generator(iterator, \n",
    "                            validation_data = (X_test, y_test_oh), \n",
    "                            epochs = 25)\n",
    "model_history = pd.DataFrame(history.history)\n",
    "model_history['epoch'] = history.epoch\n",
    "\n",
    "model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos resultados, vemos como se alcanza una precisión del ~90% para el conjunto de training, y una precisión que oscila entre el 85% y el 95% en el conjunto de test. Se observa una tendencia creciente en la precisión del conjunto de entrenamiento, por lo que es posible que los resultados mejorasen en caso de computarse más iteraciones.\n",
    "\n",
    "Procedemos a obtener la predicción de nuestro modelo sobre los datos de test y la obtención de la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 5s 295ms/step\n",
      "[2 1 0 0 0 0 1 1 2 0 2 2 0 0 0 2 0 2 0 1 1 0 0 1 2 2 0 0 2 0 2 0 1 2 0 0 1\n",
      " 0 2 2 0 1 0 1 1 2 2 1 0 2 0 2 0 1 0 1 1 2 2 1 1 2 0 2 0 1 1 0 2 1 0 2 0 1\n",
      " 1 0 2 0 0 1 0 2 2 1 2 0 0 1 2 0 2 2 2 0 0 1 1 2 0 2 0 1 0 0 0 0 2 1 1 2 0\n",
      " 2 1 1 0 2 1 1 0 1 0 0 0 2 2 0 0 2 1 0 1 1 0 1 2 1 1 0 2 0 1 0 0 2 0 0 0 0\n",
      " 1 1 1 0 2 1 1 2 0 0 2 1 1 0 0 0 2 2 0 1 2 2 0 2 2 0 0 0 2 0 2 0 2 1 0 1 2\n",
      " 2 2 0 1 1 2 2 2 1 1 0 1 2 0 1 2 1 0 2 1 1 1 0 0 1 0 0 0 0 2 1 2 1 1 0 2 2\n",
      " 0 2 0 0 0 0 0 0 0 0 1 2 1 0 0 1 1 2 2 2 1 2 0 0 1 2 0 0 0 2 2 0 1 2 1 0 1\n",
      " 2 0 0 2 2 0 2 1 0 1 0 1 0 0 2 0 2 0 0 2 1 0 2 2 1 0 1 2 1 2 0 2 1 0 0 1 1\n",
      " 0 1 0 2 0 1 1 2 0 0 0 2 1 0 1 2 0 0 0 2 2 0 0 1 0 0 0 2 1 0 2 2 2 1 2 2 1\n",
      " 1 0 2 1 0 2 2 0 2 1 0 0 0 1 2 2 0 0 2 2 2 0 2 2 0 2 1 1 1 0 1 2 0 0 0 1 0\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "class_pred = y_pred.argmax(axis = 1)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la matriz de confusión, utilizaremos la función ``confusion_matrix`` del módulo ``math`` de ``TensorFlow``. De los resultados, puede observarse como obtenemos el mayor número de aciertos (true positives, valores de la diagonal) para las clases 0 y 2. Sin embargo, para la clase 1 parece generar un mayor número de confusiones (105 aciertos frente a 19 fallos), lo que supone la principal fuente de pérdida de precisión en nuestras predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[124,   0,   0],\n",
       "       [ 15, 105,   4],\n",
       "       [ 13,   0, 111]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(y_test, class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en conjunto de entrenamiento -> 0.9611111283302307\n",
      "Accuracy en conjunto de test -> 0.9139785170555115\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos la exactitud tanto en el conjunto de entrenamiento como en el de test\n",
    "_, train_acc = model.evaluate(X_train, y_train_oh, verbose = 0)\n",
    "_, test_acc = model.evaluate(X_test, y_test_oh, verbose = 0)\n",
    "\n",
    "print(f'Accuracy en conjunto de entrenamiento -> {train_acc}')\n",
    "print(f'Accuracy en conjunto de test -> {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si realizamos un plot de la evolución de la *acurracy* del conjunto de test y entrenamiento frente al número de iteraciones, podemos observar dos tendencias.\n",
    "\n",
    "1.- El conjunto de entrenamiento presenta una tendencia claramente ascendente que podría mejorar a mayor número de iteraciones.\n",
    "\n",
    "2.- En el conjunto de test la precisión parece oscilar alrededor del 70-90% en las últimas iteraciones del modelo. Esto puede llevarnos a pensar que se necesitan más iteraciones para lograr un mejor ajuste o quizá una selección distinta de la topología y/o hiperparámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "fig.suptitle('Accuracy for test and training sets')\n",
    "plt.plot(model_history['accuracy'], label = 'train')\n",
    "plt.plot(model_history['val_accuracy'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
