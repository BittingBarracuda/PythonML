{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Bagging* y *Boosting* para un problema de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a trabajar con el Data Set *Fish Market* que contiene información referente a las dimensiones de varias especies de pescado que se venden de forma habitual en el mercado. Vamos a comenzar realizando la carga del fichero .csv mediante ``pandas``.\n",
    "\n",
    "https://www.kaggle.com/datasets/aungpyaeap/fish-market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
       "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Fish.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como este Data Set cuenta con 7 columnas. Para nuestro experimento vamos a tomar la columna ``Weight`` como variable dependiente, y el resto como variables independientes. Realizaremos una regresión lineal múltiple con el objetivo de poder predecir el peso de un patrón a partir de los valores de sus dimensiones y su especie. \n",
    "\n",
    "A continuación vamos a separar el conjunto de datos en variables de entrada y variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de entrada -> (159, 6)\n",
      "Dimensiones de variable objetivo -> (159,)\n"
     ]
    }
   ],
   "source": [
    "X = df[['Species', 'Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
    "Y = df['Weight']\n",
    "\n",
    "print(f'Dimensiones de entrada -> {X.shape}')\n",
    "print(f'Dimensiones de variable objetivo -> {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perch        56\n",
       "Bream        35\n",
       "Roach        20\n",
       "Pike         17\n",
       "Smelt        14\n",
       "Parkki       11\n",
       "Whitefish     6\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un paso adicional antes de proceder con la fase de entrenamiento consistiría en aplicar un escalado de los datos y transformar la variable ``Species`` en numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Species_Bream</th>\n",
       "      <th>Species_Parkki</th>\n",
       "      <th>Species_Perch</th>\n",
       "      <th>Species_Pike</th>\n",
       "      <th>Species_Roach</th>\n",
       "      <th>Species_Smelt</th>\n",
       "      <th>Species_Whitefish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length1  Length2  Length3   Height   Width  Species_Bream  Species_Parkki  \\\n",
       "0     23.2     25.4     30.0  11.5200  4.0200              1               0   \n",
       "1     24.0     26.3     31.2  12.4800  4.3056              1               0   \n",
       "2     23.9     26.5     31.1  12.3778  4.6961              1               0   \n",
       "3     26.3     29.0     33.5  12.7300  4.4555              1               0   \n",
       "4     26.5     29.0     34.0  12.4440  5.1340              1               0   \n",
       "\n",
       "   Species_Perch  Species_Pike  Species_Roach  Species_Smelt  \\\n",
       "0              0             0              0              0   \n",
       "1              0             0              0              0   \n",
       "2              0             0              0              0   \n",
       "3              0             0              0              0   \n",
       "4              0             0              0              0   \n",
       "\n",
       "   Species_Whitefish  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random, time\n",
    "\n",
    "seed = random.seed(time.time())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = seed)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez aplicadas las transformaciones convenientes y separados los conjuntos de test y entrenamiento, vamos a proceder a la fase de experimentación. En concreto, vamos a realizar la regresión descrita previamente utilizando el modelo base, un *ensemble* con *Bagging* y otro *ensemble* con *Boosting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE con modelo base: 104.61887570908858\n",
      "R^2 con modelo base 0.91898148175618\n",
      "----------------------------------------------------------\n",
      "RMSE con Bagging: 148.34644745257935\n",
      "R^2 con Bagging 0.8371009694029896\n",
      "----------------------------------------------------------\n",
      "RMSE con Boosting 106.74704648758177\n",
      "R^2 con Boosting 0.9156517776365352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "\n",
    "base_model = LinearRegression()\n",
    "\n",
    "# Ajuste con el modelo base\n",
    "base_model.fit(X_train, y_train)\n",
    "y_pred_1 = base_model.predict(X_test)\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, y_pred_1))\n",
    "\n",
    "# Ajuste con Bagging\n",
    "model_bag = BaggingRegressor(base_estimator = base_model, n_estimators = 100, \n",
    "                            max_samples = 0.1, random_state = seed)\n",
    "model_bag.fit(X_train, y_train)\n",
    "y_pred_2 = model_bag.predict(X_test)\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, y_pred_2))\n",
    "\n",
    "# Ajuste con Boosting\n",
    "model_boost = AdaBoostRegressor(base_estimator = base_model, n_estimators = 100, \n",
    "                                random_state = seed)\n",
    "model_boost.fit(X_train, y_train)\n",
    "y_pred_3 = model_boost.predict(X_test)\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, y_pred_3))\n",
    "\n",
    "print(f'RMSE con modelo base: {rmse_1}')\n",
    "print(f'R^2 con modelo base {r2_score(y_test, y_pred_1)}')\n",
    "print('----------------------------------------------------------')\n",
    "print(f'RMSE con Bagging: {rmse_2}')\n",
    "print(f'R^2 con Bagging {r2_score(y_test, y_pred_2)}')\n",
    "print('----------------------------------------------------------')\n",
    "print(f'RMSE con Boosting {rmse_3}')\n",
    "print(f'R^2 con Boosting {r2_score(y_test, y_pred_3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, al contrario de lo que se podría haber razonado en un principio, los modelos con *boosting* y *bagging* ofrecen un rendimiento peor que el modelo base (especialmente notable en el caso de *bagging*). Esto es así porque los modelos de varianza baja no se suelen beneficiar de este tipo de estrategias de entrenamiento.\n",
    "\n",
    "Un modelo con baja varianza es aquel que tiende a generar modelos más simples y evitar el *overfitting*. Un ejemplo de modelo de baja varianza podría ser la regresión lineal que nos indica la \"tendencia\" de los datos, pero no se ajusta perfectamente a ellos. Un ejemplo de modelo con alta varianza podrían ser los árboles de decisión que, cuando no se les aplica alguna estrategia de poda, generan un alto número de nodos \"puros\" con tendencia a sobreajustarse a los datos.\n",
    "\n",
    "En este caso concreto, el modelo base ofrece un coeficiente de correlación $R^{2}$ ~0.90 por lo que resulta adecuado para realizar predicciones de posibles nuevas entradas. Los modelos de *bagging* y *boosting* generan cierto número de estimadores (en este caso hemos fijado ``n_estimators`` a 100) y finalmente calculan el resultado de la predicción como una media de las salidas de cada estimador (media aritética en *bagging* y ponderada en *boosting*). Sin embargo, en *bagging* sabemos que los puntos se escogen con reemplazo, es decir, pueden existir puntos duplicados en varios estimadores. Este duplicado puede hacer que ciertos puntos tengan más influencia que otros a la hora de realizar predicciones y, en consecuencia, que las líneas de regresión se alejen de las que habríamos obtenido con el modelo base.\n",
    "\n",
    "Por tanto, las técnicas de ensemble resultan inadecuadas para modelos con varianza baja y es habitual obtener resultados ligeramente peores que aplicando el modelo sin ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Bagging* y *Boosting* para un problema de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el apartado de clasificación de esta actividad, vamos a hacer uso del *Pima Indians Diabetes Database* que determina si un paciente padece o no diabetes en funcion de ciertos parámetros de salud. Utilizaremos ``pandas`` y su función ``read_csv()`` para realizar la lectura del fichero.\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d = pd.read_csv('./diabetes.csv', header = 0)\n",
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, nos enfrentamos a un dataset notablemente desequilibrado, pues existen muchas más instancias de la clase \"0\" (no diabetes) que de la clase \"1\" (diabetes). Utilizaremos la ``balanced_accuracy`` como métrica del rendimiento de los modelos que generemos pues, como hemos visto en numerosas ocasiones, es robusta frente a data sets desequilibrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El data set cuenta únicamente con entradas numéricas, por lo que no es necesario reemplazar ninguna variable categórica mediante *one-hot encoding*. En este caso vamos a hacer uso de ``DecisionTreeClassifier`` como modelo base y, por tanto, no se hace necesario realizar ningún escalado o normalizado de los datos (pues este modelo no se basa en distancias). Procedemos a continuación a separar nuestro data set en conjunto de entrenamiento y conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 8)\n",
      "(231, 8)\n",
      "(537,)\n",
      "(231,)\n"
     ]
    }
   ],
   "source": [
    "X = df_d[df_d.columns[:-1]]\n",
    "Y = df_d['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = seed)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "max_depths = list(range(3, 15)) + [None]\n",
    "baccs = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "\n",
    "    base_model = DecisionTreeClassifier(max_depth = max_depth)\n",
    "\n",
    "    # Ajuste con el modelo base\n",
    "    base_model.fit(X_train, y_train)\n",
    "    y_pred_1 = base_model.predict(X_test)\n",
    "    ba_1 = balanced_accuracy_score(y_test, y_pred_1)\n",
    "\n",
    "    # Ajuste con Bagging\n",
    "    model_bag = BaggingClassifier(base_estimator = base_model, n_estimators = 100, \n",
    "                                max_samples = 0.1, random_state = seed)\n",
    "    model_bag.fit(X_train, y_train)\n",
    "    y_pred_2 = model_bag.predict(X_test)\n",
    "    ba_2 = balanced_accuracy_score(y_test, y_pred_2)\n",
    "\n",
    "    # Ajuste con Boosting\n",
    "    model_boost = AdaBoostClassifier(base_estimator = base_model, n_estimators = 100, \n",
    "                                    random_state = seed)\n",
    "    model_boost.fit(X_train, y_train)\n",
    "    y_pred_3 = model_boost.predict(X_test)\n",
    "    ba_3 = balanced_accuracy_score(y_test, y_pred_3)\n",
    "\n",
    "    baccs.append([ba_1, ba_2, ba_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento óptimo con: \n",
      "\t-Balanced Accuracy = 0.7851851851851852\n",
      "\t-max_depth = 9\n",
      "\t-Boosting\n",
      "\n",
      "Mejor rendimiento con Modelo Base\n",
      "\t-Balanced Accuracy = 0.7708641975308642\n",
      "\t-max_depth = 4\n",
      "\n",
      "Mejor rendimiento con Bagging\n",
      "\t-Balanced Accuracy = 0.7766666666666666\n",
      "\t-max_depth = 8\n",
      "\n",
      "Mejor rendimiento con Boosting\n",
      "\t-Balanced Accuracy = 0.7851851851851852\n",
      "\t-max_depth = 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baccs_aux = np.array(baccs)\n",
    "pos1, pos2 = np.unravel_index(baccs_aux.argmax(), baccs_aux.shape)\n",
    "\n",
    "words = ['Modelo Base', 'Bagging', 'Boosting']\n",
    "print(f'Rendimiento óptimo con: \\n\\t-Balanced Accuracy = {baccs_aux[pos1][pos2]}\\n\\t-max_depth = {max_depths[pos1]}\\n\\t-{words[pos2]}\\n')\n",
    "\n",
    "maxes = np.argmax(baccs_aux, axis = 0)\n",
    "print(f'Mejor rendimiento con Modelo Base\\n\\t-Balanced Accuracy = {baccs_aux[maxes[0]][0]}\\n\\t-max_depth = {max_depths[maxes[0]]}\\n')\n",
    "print(f'Mejor rendimiento con Bagging\\n\\t-Balanced Accuracy = {baccs_aux[maxes[1]][1]}\\n\\t-max_depth = {max_depths[maxes[1]]}\\n')\n",
    "print(f'Mejor rendimiento con Boosting\\n\\t-Balanced Accuracy = {baccs_aux[maxes[2]][2]}\\n\\t-max_depth = {max_depths[maxes[2]]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema particular vemos como el modelo entrenado mediante *Boosting* parece ofrecer un rendimiento superior. Sin embargo, la diferencia entre modelos no es demasiado significativa (~2% entre *Bagging* y *Boosting* y ~4% entre modelo base y *Boosting*). El mejor rendimiento de *boosting* podría atribuirse a la optimización entre predictores al dar un mayor peso a aquellas instancias mal clasificadas. \n",
    "\n",
    "De nuevo, estas diferencias no parecen demasiado significativas para este problema concreto. En general, modelos que tienden al *overfitting* como los *decision trees* se benefician de *bagging* en lugar de *boosting* ya que este último suele encontrar un mayor ajuste sobre el conjunto de datos. Por tanto, es posible que para otro tipo de problemas, el modelo de *decision tree* se beneficiase de una técnica de *bagging*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
