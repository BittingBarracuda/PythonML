{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba8f6c7",
   "metadata": {},
   "source": [
    "# Carga del dataset *Climate Model Simulation Crashes*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec47e4",
   "metadata": {},
   "source": [
    "Para comenzar con esta actividad, realizamos la carga del *Climate Model Simulation Crashes Data Set* disponible en la plataforma *UCI Machine Learning Repository* (https://archive.ics.uci.edu/ml/datasets/climate+model+simulation+crashes)\n",
    "\n",
    "Comenzamos realizando la carga mediante ``pandas``. En este caso, el archivo proporcionado contiene una cabecera con los identificadores de cada columna. Sin embargo, el fichero presentaba una dificultad adicional y es que cada columna estaba separada por un número aparentemente arbitrario de espacios, lo que complicaba su lectura. Para solventar este error, se abrió dicho fichero desde *VS Code* y, mediante el uso de la expresión regular \" +\", se reemplazaron todos los espacios por una coma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2c2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape -> (540, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Run</th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>...</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>0.298838</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.567947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.104226</td>\n",
       "      <td>0.869091</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.796997</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606041</td>\n",
       "      <td>0.457728</td>\n",
       "      <td>0.359448</td>\n",
       "      <td>0.306957</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.934851</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616870</td>\n",
       "      <td>0.975786</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.845247</td>\n",
       "      <td>0.864152</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.356573</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.512256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.618903</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.195928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.803413</td>\n",
       "      <td>0.643995</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.924775</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.365858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.421837</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.490828</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471463</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>0.362751</td>\n",
       "      <td>0.912819</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.475987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.844798</td>\n",
       "      <td>0.441502</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.487546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551543</td>\n",
       "      <td>0.743877</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.650223</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.132283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study  Run  vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  vconst_7  \\\n",
       "0      1    1     0.859036  0.927825  0.252866  0.298838  0.170521  0.735936   \n",
       "1      1    2     0.606041  0.457728  0.359448  0.306957  0.843331  0.934851   \n",
       "2      1    3     0.997600  0.373238  0.517399  0.504993  0.618903  0.605571   \n",
       "3      1    4     0.783408  0.104055  0.197533  0.421837  0.742056  0.490828   \n",
       "4      1    5     0.406250  0.513199  0.061812  0.635837  0.844798  0.441502   \n",
       "\n",
       "    ah_corr  ah_bolus  ...  efficiency_factor  tidal_mix_max  \\\n",
       "0  0.428325  0.567947  ...           0.245675       0.104226   \n",
       "1  0.444572  0.828015  ...           0.616870       0.975786   \n",
       "2  0.746225  0.195928  ...           0.679355       0.803413   \n",
       "3  0.005525  0.392123  ...           0.471463       0.597879   \n",
       "4  0.191926  0.487546  ...           0.551543       0.743877   \n",
       "\n",
       "   vertical_decay_scale  convect_corr  bckgrnd_vdc1  bckgrnd_vdc_ban  \\\n",
       "0              0.869091      0.997518      0.448620         0.307522   \n",
       "1              0.914344      0.845247      0.864152         0.346713   \n",
       "2              0.643995      0.718441      0.924775         0.315371   \n",
       "3              0.761659      0.362751      0.912819         0.977971   \n",
       "4              0.312349      0.650223      0.522261         0.043545   \n",
       "\n",
       "   bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  outcome  \n",
       "0        0.858310          0.796997  0.869893        0  \n",
       "1        0.356573          0.438447  0.512256        1  \n",
       "2        0.250642          0.285636  0.365858        1  \n",
       "3        0.845921          0.699431  0.475987        1  \n",
       "4        0.376660          0.280098  0.132283        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'pop_failures.dat'\n",
    "df = pd.read_csv(filename)\n",
    "print(f'Shape -> {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a0b51",
   "metadata": {},
   "source": [
    "# Conteo de clases y desequilibrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16155007",
   "metadata": {},
   "source": [
    "Procedemos a hacer un conteo de las diferentes clases en el dataset haciendo uso del método ``.value_counts()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9663b9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    494\n",
       "0     46\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6dee06",
   "metadata": {},
   "source": [
    "Como podemos observar, el dataset cuenta con un desequilibrado notable de los datos. En concreto, contamos con 540 datos, el ~91.48% etiquetados como \"1\" y el resto como \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee82d7",
   "metadata": {},
   "source": [
    "# Segmentado en conjunto de entrenamiento y conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a5104",
   "metadata": {},
   "source": [
    "En este caso, vamos a realizar una validación cruzada para determinar el rendimiento de los modelos a entrenar. Por tanto a continuación únicamente separaremos variables de entrada y variable objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2b47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "Y = df['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a472f49",
   "metadata": {},
   "source": [
    "# Normalizado de las variables de entrada numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c279176",
   "metadata": {},
   "source": [
    "Para realizar el normalizado de las variables, haremos uso de ``RobustScaler`` que, como ya vimos en lecciones anteriores, permite realizar un normalizado robusto a posibles *outliers* dentro de nuestro DataSet. Utilizaremos además la función ``fit_transform()`` para realizar el normalizado en un solo paso. Sin embargo, antes de proceder, eliminaremos las variables correspondientes a las dos primeras columnas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c858cab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>slm_corr</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>0.298838</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.567947</td>\n",
       "      <td>0.474370</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.104226</td>\n",
       "      <td>0.869091</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.796997</td>\n",
       "      <td>0.869893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.606041</td>\n",
       "      <td>0.457728</td>\n",
       "      <td>0.359448</td>\n",
       "      <td>0.306957</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.934851</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>0.296618</td>\n",
       "      <td>0.616870</td>\n",
       "      <td>0.975786</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.845247</td>\n",
       "      <td>0.864152</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.356573</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.512256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.618903</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.195928</td>\n",
       "      <td>0.815667</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.803413</td>\n",
       "      <td>0.643995</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.924775</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.365858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.421837</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.490828</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.471463</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>0.362751</td>\n",
       "      <td>0.912819</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.475987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.844798</td>\n",
       "      <td>0.441502</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.487546</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0.551543</td>\n",
       "      <td>0.743877</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.650223</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.132283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.657136</td>\n",
       "      <td>0.489375</td>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.411950</td>\n",
       "      <td>0.087780</td>\n",
       "      <td>0.356289</td>\n",
       "      <td>0.480204</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>0.400102</td>\n",
       "      <td>0.280546</td>\n",
       "      <td>0.384117</td>\n",
       "      <td>0.885948</td>\n",
       "      <td>0.768482</td>\n",
       "      <td>0.459479</td>\n",
       "      <td>0.334482</td>\n",
       "      <td>0.573002</td>\n",
       "      <td>0.610183</td>\n",
       "      <td>0.737706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.915894</td>\n",
       "      <td>0.842720</td>\n",
       "      <td>0.518947</td>\n",
       "      <td>0.090622</td>\n",
       "      <td>0.336981</td>\n",
       "      <td>0.893576</td>\n",
       "      <td>0.978703</td>\n",
       "      <td>0.674868</td>\n",
       "      <td>0.263398</td>\n",
       "      <td>0.798108</td>\n",
       "      <td>0.353546</td>\n",
       "      <td>0.044796</td>\n",
       "      <td>0.990900</td>\n",
       "      <td>0.347027</td>\n",
       "      <td>0.512499</td>\n",
       "      <td>0.810549</td>\n",
       "      <td>0.593332</td>\n",
       "      <td>0.142565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.941185</td>\n",
       "      <td>0.769245</td>\n",
       "      <td>0.950776</td>\n",
       "      <td>0.189406</td>\n",
       "      <td>0.112743</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.527096</td>\n",
       "      <td>0.870987</td>\n",
       "      <td>0.193103</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.101506</td>\n",
       "      <td>0.548878</td>\n",
       "      <td>0.381966</td>\n",
       "      <td>0.198811</td>\n",
       "      <td>0.867108</td>\n",
       "      <td>0.461632</td>\n",
       "      <td>0.652817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.779287</td>\n",
       "      <td>0.867468</td>\n",
       "      <td>0.704820</td>\n",
       "      <td>0.983282</td>\n",
       "      <td>0.420303</td>\n",
       "      <td>0.710612</td>\n",
       "      <td>0.174746</td>\n",
       "      <td>0.267685</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.436714</td>\n",
       "      <td>0.690132</td>\n",
       "      <td>0.825133</td>\n",
       "      <td>0.981656</td>\n",
       "      <td>0.113193</td>\n",
       "      <td>0.364799</td>\n",
       "      <td>0.201469</td>\n",
       "      <td>0.536535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.608075</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>0.598264</td>\n",
       "      <td>0.794771</td>\n",
       "      <td>0.145680</td>\n",
       "      <td>0.378183</td>\n",
       "      <td>0.461948</td>\n",
       "      <td>0.425291</td>\n",
       "      <td>0.057396</td>\n",
       "      <td>0.480938</td>\n",
       "      <td>0.307816</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>0.464152</td>\n",
       "      <td>0.583558</td>\n",
       "      <td>0.969365</td>\n",
       "      <td>0.464331</td>\n",
       "      <td>0.760344</td>\n",
       "      <td>0.762439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  vconst_7   ah_corr  \\\n",
       "0       0.859036  0.927825  0.252866  0.298838  0.170521  0.735936  0.428325   \n",
       "1       0.606041  0.457728  0.359448  0.306957  0.843331  0.934851  0.444572   \n",
       "2       0.997600  0.373238  0.517399  0.504993  0.618903  0.605571  0.746225   \n",
       "3       0.783408  0.104055  0.197533  0.421837  0.742056  0.490828  0.005525   \n",
       "4       0.406250  0.513199  0.061812  0.635837  0.844798  0.441502  0.191926   \n",
       "..           ...       ...       ...       ...       ...       ...       ...   \n",
       "535     0.657136  0.489375  0.133713  0.411950  0.087780  0.356289  0.480204   \n",
       "536     0.915894  0.842720  0.518947  0.090622  0.336981  0.893576  0.978703   \n",
       "537     0.478600  0.941185  0.769245  0.950776  0.189406  0.112743  0.745645   \n",
       "538     0.007793  0.779287  0.867468  0.704820  0.983282  0.420303  0.710612   \n",
       "539     0.608075  0.031556  0.598264  0.794771  0.145680  0.378183  0.461948   \n",
       "\n",
       "     ah_bolus  slm_corr  efficiency_factor  tidal_mix_max  \\\n",
       "0    0.567947  0.474370           0.245675       0.104226   \n",
       "1    0.828015  0.296618           0.616870       0.975786   \n",
       "2    0.195928  0.815667           0.679355       0.803413   \n",
       "3    0.392123  0.010015           0.471463       0.597879   \n",
       "4    0.487546  0.358534           0.551543       0.743877   \n",
       "..        ...       ...                ...            ...   \n",
       "535  0.029678  0.400102           0.280546       0.384117   \n",
       "536  0.674868  0.263398           0.798108       0.353546   \n",
       "537  0.527096  0.870987           0.193103       0.829563   \n",
       "538  0.174746  0.267685           0.761134       0.436714   \n",
       "539  0.425291  0.057396           0.480938       0.307816   \n",
       "\n",
       "     vertical_decay_scale  convect_corr  bckgrnd_vdc1  bckgrnd_vdc_ban  \\\n",
       "0                0.869091      0.997518      0.448620         0.307522   \n",
       "1                0.914344      0.845247      0.864152         0.346713   \n",
       "2                0.643995      0.718441      0.924775         0.315371   \n",
       "3                0.761659      0.362751      0.912819         0.977971   \n",
       "4                0.312349      0.650223      0.522261         0.043545   \n",
       "..                    ...           ...           ...              ...   \n",
       "535              0.885948      0.768482      0.459479         0.334482   \n",
       "536              0.044796      0.990900      0.347027         0.512499   \n",
       "537              0.101506      0.548878      0.381966         0.198811   \n",
       "538              0.690132      0.825133      0.981656         0.113193   \n",
       "539              0.231638      0.464152      0.583558         0.969365   \n",
       "\n",
       "     bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  \n",
       "0          0.858310          0.796997  0.869893  \n",
       "1          0.356573          0.438447  0.512256  \n",
       "2          0.250642          0.285636  0.365858  \n",
       "3          0.845921          0.699431  0.475987  \n",
       "4          0.376660          0.280098  0.132283  \n",
       "..              ...               ...       ...  \n",
       "535        0.573002          0.610183  0.737706  \n",
       "536        0.810549          0.593332  0.142565  \n",
       "537        0.867108          0.461632  0.652817  \n",
       "538        0.364799          0.201469  0.536535  \n",
       "539        0.464331          0.760344  0.762439  \n",
       "\n",
       "[540 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(['Study', 'Run'], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33abe80f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71751352,  0.85918326, -0.49682123, ...,  0.71750992,\n",
       "         0.60113527,  0.74082277],\n",
       "       [ 0.21191974, -0.08400007, -0.28264478, ..., -0.28828816,\n",
       "        -0.1220402 ,  0.02564715],\n",
       "       [ 0.99442345, -0.25351739,  0.03475513, ..., -0.50064096,\n",
       "        -0.43025281, -0.26710902],\n",
       "       ...,\n",
       "       [-0.04276343,  0.8859888 ,  0.54083458, ...,  0.7351464 ,\n",
       "        -0.07527832,  0.30673092],\n",
       "       [-0.9836394 ,  0.56116406,  0.73821232, ..., -0.27179948,\n",
       "        -0.60001161,  0.07419914],\n",
       "       [ 0.21598363, -0.93905727,  0.19725104, ..., -0.07227361,\n",
       "         0.52720718,  0.52594499]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "X = RobustScaler().fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2980f",
   "metadata": {},
   "source": [
    "Una vez nos hemos asegurado que todas las variables del conjunto de entrenamiento son de tipo numérico, podemos comenzar a entrenar nuestro modelo SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd1239",
   "metadata": {},
   "source": [
    "# Evaluación del rendimento de un modelo SVM con diferentes parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d4947",
   "metadata": {},
   "source": [
    "A continuación vamos a realizar un entrenamiento de varios modelos de tipo SVM con diferentes parámetros. En concreto estudiaremos los siguientes tipos de parámetro:\n",
    "\n",
    "- Función de kernel a utilizar: Lineal, Polinómico, Gaussiano y Sigmoide\n",
    "- Valor del parámetro ``C`` de regularización.\n",
    "- El parámetro ``gamma`` en los tipos de Kernel que lo admitan.\n",
    "\n",
    "Además, debemos tener en cuenta que nuestro dataset se encuentra desequilibrado, por lo que utilizaremos el parámetro ``class_weight = balanced``. De nuevo, como en lecciones anteriores haremos uso de la ``balanced_accuracy`` como métrica del rendimiento, pues proporciona una intuición correcta de la precisión de clasificación en cada clase. En concreto, usaremos validación cruzada de *Monte Carlo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ef066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "CONFIGURACION OPTIMA\n",
      "Balanced Accuracy -> 0.8869490826633685\n",
      "Kernel -> rbf\n",
      "C -> 1\n",
      "Gamma -> 0.1\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "CONFIGURACION OPTIMA LINEAR\n",
      "Balanced Accuracy -> 0.8637662337662337\n",
      "Kernel -> linear\n",
      "C -> 1000\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "# Comenzamos definiendo los parámetros que vamos a usar\n",
    "# Posibles valores de la función de Kernel\n",
    "kernels = ['poly', 'rbf', 'sigmoid']\n",
    "# Posibles valores del parámetro de regularización C\n",
    "# Valores pequeños -> Se toleran más errores de clasificación, menos overfitting\n",
    "# Valores grandes -> Se toleran menos errores de clasficación, mayor overfitting\n",
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "# Posibles valores del parámetro gamma\n",
    "gammas = [1, 0.1, 0.001, 0.001]\n",
    "\n",
    "# Incializamos una semilla para poder replicar el reparto\n",
    "seed = random.randint(0, 10)\n",
    "monte_carlo = ShuffleSplit(n_splits = 100, test_size = 0.3, random_state = seed)\n",
    "\n",
    "# Comenzamos entrenando todos los modelos, generaremos un Array 3-D que contendrá\n",
    "# los resultados para cada tipo de kernel, con cada valor de C y Gamma.\n",
    "baccs = [[[]]]\n",
    "i, j = 0, 0\n",
    "# Iteramos sobre los kernels\n",
    "for kernel in kernels:\n",
    "    # Iteramos sobre las Cs\n",
    "    for c in Cs:\n",
    "        # Iteramos sobre los valores de Gamma\n",
    "        for gamma in gammas:\n",
    "            # Entrenamos el modelo con la combinación de parámetros\n",
    "            model_temp = SVC(C = c, kernel = kernel, gamma = gamma, class_weight = 'balanced')\n",
    "            # Obtenemos el valor de Balanced Accuracy mediante validación cruzada\n",
    "            # con Monte Carlo\n",
    "            res_mc_temp = cross_val_score(model_temp, X, Y, scoring = 'balanced_accuracy')\n",
    "            # Almacenamos la media de las balanced accuracy obtenidas\n",
    "            baccs[i][j].append(res_mc_temp.mean())\n",
    "        baccs[i].append([])\n",
    "        j = j + 1\n",
    "    baccs[-1].pop()\n",
    "    baccs.append([])\n",
    "    baccs[-1].append([])\n",
    "    i, j = i + 1, 0\n",
    "baccs.pop()\n",
    "\n",
    "# Realizamos el mismo experimento con kernel = 'linear' pero sin gamma\n",
    "baccs_linear = []\n",
    "for c in Cs:\n",
    "    model_temp = SVC(C = c, kernel = 'linear', class_weight = 'balanced')\n",
    "    res_mc_temp = cross_val_score(model_temp, X, Y, scoring = 'balanced_accuracy')\n",
    "    baccs_linear.append(res_mc_temp.mean())\n",
    "\n",
    "\n",
    "# Obtenemos la posición de la máxima Balanced Accuracy en el Array 3-D generado\n",
    "baccs_aux = np.array(baccs)\n",
    "i, j, k = np.unravel_index(baccs_aux.argmax(), baccs_aux.shape)\n",
    "# Mostramos los parámetros óptimos para el experimento\n",
    "print('--------------------------------------------------------')\n",
    "print(f'CONFIGURACION OPTIMA\\nBalanced Accuracy -> {baccs_aux.max()}')\n",
    "print(f'Kernel -> {kernels[i]}\\nC -> {Cs[j]}\\nGamma -> {gammas[k]}')\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "# Obtenemos lo mismo para el caso de linear\n",
    "baccs_linear_aux = np.array(baccs_linear)\n",
    "i = np.argmax(baccs_linear_aux)\n",
    "print('--------------------------------------------------------')\n",
    "print(f'CONFIGURACION OPTIMA LINEAR\\nBalanced Accuracy -> {baccs_linear_aux.max()}')\n",
    "print(f'Kernel -> linear\\nC -> {Cs[i]}')\n",
    "print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ff263c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.65321171, 0.57591837, 0.57591837, 0.57591837],\n",
       "        [0.65321171, 0.71361575, 0.5       , 0.5       ],\n",
       "        [0.65321171, 0.65423212, 0.5       , 0.5       ],\n",
       "        [0.65321171, 0.65321171, 0.69713049, 0.69713049],\n",
       "        [0.65321171, 0.65321171, 0.5       , 0.5       ]],\n",
       "\n",
       "       [[0.5       , 0.87267368, 0.55714286, 0.55714286],\n",
       "        [0.5       , 0.88694908, 0.82744795, 0.82744795],\n",
       "        [0.5       , 0.78736343, 0.87067409, 0.87067409],\n",
       "        [0.5       , 0.79736343, 0.87487734, 0.87487734],\n",
       "        [0.5       , 0.79736343, 0.86174603, 0.86174603]],\n",
       "\n",
       "       [[0.84018759, 0.86546073, 0.61673882, 0.61673882],\n",
       "        [0.79973201, 0.85654298, 0.5       , 0.5       ],\n",
       "        [0.79165121, 0.88066378, 0.87153164, 0.87153164],\n",
       "        [0.79065141, 0.87067409, 0.85960421, 0.85960421],\n",
       "        [0.80883323, 0.86250258, 0.85164502, 0.85164502]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baccs_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1111d641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85960421, 0.85164502, 0.86073593, 0.86073593, 0.86376623])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baccs_linear_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcae83",
   "metadata": {},
   "source": [
    "De las salidas anteriores podemos ver como el valor óptimo de los parámetros es:\n",
    "\n",
    "- Kernel: RBF\n",
    "- C = 1\n",
    "- $\\gamma$ = 0.1\n",
    "\n",
    "ofriciendo una *balanced accuracy* del ~88.7%. Otros aspectos relevantes a comentar son los siguientes:\n",
    "\n",
    "- El kernel polinómico ofrece unos resultados claramente inferiores para este problema.\n",
    "- RBF y Sigmoid ofrecen un rendimento similar.\n",
    "- Valores bajos de C y altos en $\\gamma$ parecen empeorar el valor de la precisión para las tres funciones de Kernel.\n",
    "- El kernel lineal ofrece una precisión ~85% independientemente del valor de C pero el mejor valor se obtiene con C = 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d98108",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "12749f567798517b8543354a13719bbd42e9e3e56a89ba27a040f4f72d5c2230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
